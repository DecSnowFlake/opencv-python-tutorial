{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph cut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 目标\n",
    "\n",
    "在本章，我们将要学习：\n",
    "- GraphCut 算法原理，使用GrabCut算法提取图像的前景\n",
    "- 创建一个交互式程序完成前景提取"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 原理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 用户输入一个矩形，矩形外面的所有区域肯定都是背景（所有的对象都要包含在矩形框内），矩形框内的东西是未知的，同样用户确定前景和背景的任何操作都不会被程序所改变。\n",
    "- 计算机会对我们的输入图像做一个初始化标记，它会标记前景和背景像素。\n",
    "- 使用一个高斯混合模型（GMM）对前景和背景建模\n",
    "- 根据我们的输入,GMM会学习并创建新的像素分布.对那些分类位置的像素(可能是前景也可能是背景),可以根据它们与已知分类(如背景)的像素的关系来进行分类(就像是在做聚类操作).\n",
    "- 这样就会根据像素的分布创建一幅图,图中的节点就是像素点.除了像素点之外,还有两个节点:Source_node 和 Sink_node.所有的前景像素都和Source_node相连,所有的背景像素都和Sink_node相连.\n",
    "- 将像素连接到Souece_node/Sink_node的边的权重由它们属于同一类的概率来决定.两个像素之间的权重由边的信息或者两个像素的相似性来决定.如果两个像素的颜色有很大的不同,那么它们之间的边的权重就会很小.\n",
    "- 使用mincut算法对上面得到的图进行分割,它会根据最低成本方程将图分为Source_node和Sink_node.成本方程就是被剪掉的所有边的权重之和.在裁剪之后\n",
    "    - 所有连接到Source_node的像素被认为是前景\n",
    "    - 所有链接到Sink_node的像素被认为是背景\n",
    "- 继续这个过程直到收敛"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 演示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "grabCut(img, mask, rect, bgdModel, fgdModel, iterCount[, mode]) -> mask, bgdModel, fgdModel\n",
       ".   @brief Runs the GrabCut algorithm.\n",
       ".   \n",
       ".   The function implements the [GrabCut image segmentation algorithm](http://en.wikipedia.org/wiki/GrabCut).\n",
       ".   \n",
       ".   @param img Input 8-bit 3-channel image.\n",
       ".   @param mask Input/output 8-bit single-channel mask. The mask is initialized by the function when\n",
       ".   mode is set to #GC_INIT_WITH_RECT. Its elements may have one of the #GrabCutClasses.\n",
       ".   @param rect ROI containing a segmented object. The pixels outside of the ROI are marked as\n",
       ".   \"obvious background\". The parameter is only used when mode==#GC_INIT_WITH_RECT .\n",
       ".   @param bgdModel Temporary array for the background model. Do not modify it while you are\n",
       ".   processing the same image.\n",
       ".   @param fgdModel Temporary arrays for the foreground model. Do not modify it while you are\n",
       ".   processing the same image.\n",
       ".   @param iterCount Number of iterations the algorithm should make before returning the result. Note\n",
       ".   that the result can be refined with further calls with mode==#GC_INIT_WITH_MASK or\n",
       ".   mode==GC_EVAL .\n",
       ".   @param mode Operation mode that could be one of the #GrabCutModes\n",
       "\u001b[0;31mType:\u001b[0m      builtin_function_or_method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cv2.grabCut?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
